{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Semi-Unsupervised Sentence Classification",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpQW1fbi4ZON"
      },
      "source": [
        "# Semi-Unsupervised Sentence Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh9sTd5Y4iwx"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqo-LGqIEzf_",
        "outputId": "cbc815a8-c2e2-4a24-86d2-f34b6fbde478",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "import nltk\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "!pip install nmslib \n",
        "import nmslib\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting nmslib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b5/5a/4824e7c2803db7fd9b1dbc0de9075bd552e85f4c69c6c054160f7ec92158/nmslib-2.0.5-cp36-cp36m-manylinux2010_x86_64.whl (12.9MB)\n",
            "\u001b[K     |████████████████████████████████| 13.0MB 2.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from nmslib) (1.17.5)\n",
            "Collecting pybind11>=2.2.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4b/4d/ae1c4d8e8b139afa9682054dd42df3b0e3b5c1731287933021b9fd7e9cc4/pybind11-2.4.3-py2.py3-none-any.whl (150kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 48.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from nmslib) (5.4.8)\n",
            "Installing collected packages: pybind11, nmslib\n",
            "Successfully installed nmslib-2.0.5 pybind11-2.4.3\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkdPL7UYFBYN",
        "outputId": "623f9f0b-f34b-4eaa-c59d-e9a01f2e6376",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "! mkdir NLP\n",
        "%cd NLP\n",
        "\n",
        "# !mkdir GloVe\n",
        "# !curl -Lo GloVe/glove.840B.300d.zip http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
        "# !unzip GloVe/glove.840B.300d.zip -d GloVe/\n",
        "\n",
        "!mkdir fastText\n",
        "!curl -Lo fastText/crawl-300d-2M.vec.zip https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip\n",
        "!unzip fastText/crawl-300d-2M.vec.zip -d fastText/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/NLP\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1453M  100 1453M    0     0  10.8M      0  0:02:13  0:02:13 --:--:-- 10.7M\n",
            "Archive:  fastText/crawl-300d-2M.vec.zip\n",
            "  inflating: fastText/crawl-300d-2M.vec  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_Ppt5qbFWIc",
        "outputId": "c1a0d1ef-30fd-419a-e070-bbc897812f49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!mkdir encoder\n",
        "# !curl -Lo encoder/infersent1.pkl https://dl.fbaipublicfiles.com/infersent/infersent1.pkl\n",
        "!curl -Lo encoder/infersent2.pkl https://dl.fbaipublicfiles.com/infersent/infersent2.pkl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  146M  100  146M    0     0  10.9M      0  0:00:13  0:00:13 --:--:-- 12.8M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0DkIO7PE3IL",
        "outputId": "e627738f-7672-4a05-abc2-31530189bb54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "! git clone https://github.com/facebookresearch/InferSent.git\n",
        "\n",
        "from InferSent.models import InferSent\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'InferSent'...\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 259 (delta 7), reused 13 (delta 4), pack-reused 240\u001b[K\n",
            "Receiving objects: 100% (259/259), 448.95 KiB | 632.00 KiB/s, done.\n",
            "Resolving deltas: 100% (131/131), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9anwfzEAKShy"
      },
      "source": [
        "sentences = [ \n",
        "  'Develop high-quality PHP/Python applications (web & mobile) using Magento solutions in order to support business for our Enterprise and SMB Clients.',\n",
        "  'Create, and modify websites CSS, jQuery, using Magento',\n",
        "  'Review internal custom code that integrates Magento with third party systems like ERP, Shipping, Inventory',\n",
        " 'You will work closely with the CTO as part of the core team to roadmap and leverage appropriate technologies to deliver the business strategy.',\n",
        "  'In this role, you will be responsible for the roadmap of technical development and features.',\n",
        "  'Your role may include:',\n",
        "  '• Research, prototyping, design, architecture, agile implementation, and/or leading development team.',\n",
        "  '• Design system architecture and develop robust backend and systems',\n",
        "  'The ideal candidate has:',\n",
        "  '• Strong knowledge of JavaScript and contemporary JavaScript APIs such as React.JS, JQuery, Python, Django, and/or Angular.',\n",
        "  '• Experience with design and development of highly scalable distributed systems',\n",
        "  '• Ability to work collaboratively in teams and develop meaningful relationships to achieve common goals.',\n",
        "  '• Knowledge of existing and emerging technologies',\n",
        "  '• Proven project management skills',\n",
        "  '• Technical Evangelist',\n",
        "  'Nice to have:',\n",
        "  '• Prior experience in startups, but most of all, you should have a startup mentality',\n",
        "  '• Willingness to wear many hats and a strong desire to build the business from ground up',\n",
        "  'What we offer:',\n",
        "  '• Opportunity to build an exciting, new and unique ecosystem with almost unlimited scalability',\n",
        "  '• Opportunity to have a big impact on the vision and the company',\n",
        "  '• Great team',\n",
        "  '• Flexible hours (40+hrs a week)',\n",
        "  'Apply now',\n",
        " 'Are you interested in an amazing opportunity that also makes a difference?  We help 100,000+ teachers and students learn more every school day.',\n",
        "  'To do this, we have a node stack (React, GraphQL, Apollo Client, Typescript, webpack, mongoDB, Kubernetes).',\n",
        "  ' ',\n",
        "  'If you are great with Javascript, that\\'s all we require.',\n",
        "  'We want you to be opinionated, factual, but willing to compromise. You should be comfortable both giving and receiving feedback from peers. We want to make each other better.',\n",
        "  'You will play a key role in carving out a future for our web application and for the future of education.',\n",
        "  'With your input, help and expertise we will build an application that will ultimately collect more classroom data on student learning than any in human history.  We want to use that data to help teachers, schools, parents, students and entire communities have unprecedented academic growth.',\n",
        "  '# Bonus Points If',\n",
        "  '* You\\'ve used React and Typescript',\n",
        "  '* GraphQL makes you smile',\n",
        "  '* You have implemented E2E tests on a continuous integration server',\n",
        "  '* You have implemented real-time reactivity in a project using WebSockets',\n",
        "  '* You like board games',\n",
        " 'Working at HappyFunCorp means working with great people on an interesting range of projects. Our HQ is in Brooklyn but our team spans the globe. We’re looking for folks who are friendly, hard-working, curious, and whip smart.',\n",
        "  'We are currently looking for a experienced Wordpress developer who can make clean custom plugins and modules within the Digital media sector. Experienced with PHP is essential as the project scope is backend development. ',\n",
        "  'What we look for is someone with a great attitude, experience with turning ideas into fully-fledged products. If this profile sounds like you, send us through your application!',\n",
        " 'POSITION SUMMARY AND PRIMARY RESPONSIBILITIES',\n",
        "  'We are looking for a Python developer to rapidly build and deploy features to support highly dynamic organizations. Your primary focus will be engaged in the development of backend systems, APIs, and and working within the Amazon Web Services (AWS) framework.',\n",
        "  'RESPONSIBILITIES:',\n",
        "  'Design, build, and maintain efficient, reusable, and reliable Python code',\n",
        "  'Integration of data storage solutions to include both SQL and NoSQL.',\n",
        "  'Integration of user-facing elements developed by a rockstar group of front-end developers and designers.',\n",
        "  'Identify bottlenecks and bugs, and crush them',\n",
        "  'Help maintain code quality, organization and automatization',\n",
        "  'Develop administrative backend systems to support customer operations.',\n",
        "  'ESSENTIAL SKILLS AND EXPERIENCE',\n",
        "  '5 years experience with Python',\n",
        "  'Strong experience designing and implementing APIs.',\n",
        "  'Experience securing hosts to include ssl, firewalls, and setting ssh keys',\n",
        "  'Familiarity with concepts of MVC, ORM, and SQL queries',\n",
        "  'Solid grasp on object-oriented programming',\n",
        "  'Basic understanding of front-end technologies, such as JavaScript, HTML5, and CSS3',\n",
        "  'A knack for writing clean, readable code',\n",
        "  'Experience with Linux servers and Amazon Web Services (AWS).',\n",
        "  'Understanding of fundamental design principles behind a scalable application (oCaml a plus)',\n",
        "  'Strong working knowledge of a CI tool (like Jenkins) for automated deployment and testing',\n",
        "  ' ',\n",
        "  'DESIRED EXPERIENCE AND SKILLS',\n",
        "  'Meaningful industry rapport',\n",
        "  'Demonstrated track record of success',\n",
        "  'Published articles or open source projects demonstrating command of your profession',\n",
        "  'PERSONAL ATTRIBUTES',\n",
        "  'Highly respected and well connected.',\n",
        "  'Extremely detail-oriented and exhibits outstanding judgment and professionalism.',\n",
        "  'Thrives in a fast-paced and entrepreneurial environment.',\n",
        "  'Resourceful; work independently in an entrepreneurial environment.',\n",
        "  'Adaptability to thrive in both individual and team environments; highly developed “EQ.”',\n",
        "  'Is eager to learn about new technologies.',\n",
        "  'Voracious reader of current software engineering and technical articles and books',\n",
        "  'REQUIRED EDUCATION',\n",
        "  'Bachelors in Computer Science or higher or related field.',\n",
        "  'Job Type: Full-time',\n",
        "  'Location: Hampstead, MD',\n",
        "  'Salary: Commensurate with experience',\n",
        "  'Application Questions',\n",
        "  'How many years of python experience do you have?',\n",
        "  'Have you completed the following level of education: Bachelor\\'s?',\n",
        "  'Are you within a 25 mile radius of Baltimore, MD?',\n",
        "  'Are you willing to undergo a background check, in accordance with local law/regulations?',\n",
        "  'Are you able to commute to this job\\'s location?',\n",
        "  'We only accept US citizens for this job. Are you a US citizen?',\n",
        " 'Kitsuma is seeking an experienced serverless full stack engineer to join the product development team. The position is full-time and is based in Charlotte, North Carolina, although full-time working remotely is an option. ',\n",
        "  'The programmer will own the code, test, build and release infrastructure for the application. This will include designing and implementing processes and tools to support continuous integration, testing, deployment, automation. In addition, the programmer will be an evangelist for good software engineering practices.',\n",
        " 'Help us build an amazing EdTech platform focused on helping AP students study efficiently for their exams.',\n",
        "  'You\\'ll be working on a multitude of exciting features and will need to wear a lot of hats.',\n",
        "  'This position will be contracted month-by-month with the opportunity to upgrade to an annual contract in the future.',\n",
        "  'Feel free to send me an email if you would like more information.',\n",
        " 'Sana Benefits is a tech-forward employee benefits startup seeking experienced software engineers to join our team. As a successful candidate, you have demonstrated the ability to build, deploy and maintain large-scale, distributed applications with complex database schemas. You understand and use automated testing and know how to write clean, readable code.',\n",
        "  'We are building a distributed engineering team and encourage all applicants to apply, regardless of location.',\n",
        "  'We work primarily in Ruby on Rails and JavaScript, but are open to those with differing backgrounds. You should have a deep understanding of how to build software that goes beyond the ability to use these tools.',\n",
        "  'On the job you will:',\n",
        "  '- Automate insurance claims processing',\n",
        "  '- Build internal tools to support our operations team',\n",
        "  '- Enhance our testing, monitoring and continuous deployment infrastructure',\n",
        "  '- Help keep sensitive medical data safe and secure',\n",
        "  '- Work with our operations team to build out a roadmap',\n",
        "  'About you:',\n",
        "  '- Minimum of 2 years of professional, hands-on experience',\n",
        "  '- Strong object-oriented design and coding skills',\n",
        "  '- Working knowledge of Ruby, Javascript',\n",
        "  '- Experience working with complicated systems at scale',\n",
        "  '- Solid understanding of data structures and algorithms',\n",
        "  'Tech We Use:',\n",
        "  'Rails, React, Docker, Elasticsearch, AWS, Linux, Postgres, Git',\n",
        " 'We\\'re looking for a cloud software developer who can build cloud backend services running on Serverless services on AWS and Google Cloud. ',\n",
        "  'Our cloud software developers spend their days:',\n",
        "  ' - Developing, testing and deploying cloud applications',\n",
        "  ' - Delivering code in automated build, integration, testing and deployment environments',\n",
        "  ' - Contributing to agile management in stand-ups and retrospectives',\n",
        "  ' - Collaborating with client teams and software architects across multiple projects.',\n",
        "  ' - Coaching and mentoring, pair programming and jointly developing with client teams.',\n",
        "  ' - Leading development of project workstreams, mentoring less experienced developers.',\n",
        "  ' - Being part of a technical community, supporting our team on company-wide projects.',\n",
        "  'Candidate Requirements - you’re perfect for this position if you have:',\n",
        "  ' - Experience building modern Internet and enterprise software applications.',\n",
        "  ' - Led software development work streams inside larger projects.',\n",
        "  ' - Proficiency developing in multiple languages - JavaScript/Node.js, Python, Java and Go.',\n",
        "  ' - Automated test-driven approach to software development.',\n",
        "  ' - Experience of working in CI/CD deployments with Github and AWS deployment tools.',\n",
        "  ' - Comfortable working with Agile, Lean and Pair Programming styles.',\n",
        "  ' - Experience with API Gateways, Functions, NoSQL databases, notifications and message queues.',\n",
        "  ' - Experience with GraphQL and REST API development',\n",
        "  ' - Lead the design of distributed systems',\n",
        "  ' - Accessing data across multiple datastores - SQL, NoSQL and graph databases',\n",
        "  ' - AWS associate developer or solutions architect certification (not required)',\n",
        "  'Compensation',\n",
        "  ' - A competitive salary.',\n",
        "  ' - Annual bonus based upon company and individual achievements.',\n",
        "  ' - 15 days of annual vacation allowance, plus 8 public holiday days PTO.',\n",
        "  ' - Medical, dental and vision insurance.',\n",
        "  ' - Mobile phone and home Internet allowances.',\n",
        "  ' - Professional training, conferences and certifications.',\n",
        " '■ WHAT WE DO ',\n",
        "  'We\\'ve built behavior analysis AI which detect & predict human behaviors. With the technology, we developed “VAAKEYE” to prevent crimes before it happen, and developed a checkout-less system “VAAKPAY” to reduce operations & personnels. We stay focus on social issues.',\n",
        "  '- MEDIA ',\n",
        "  'Bloomberg, Forbes, etc. published in large numbers domestically and abroad ',\n",
        "  'https://bloom.bg/2GWEM45',\n",
        "  '■ MEMBER',\n",
        "  'Technical team is comprised of researchers from international organizations, engineers from NEC, CTO experienced people (6 people) and other technically talented global members, and Biz is comprised of members such as representatives of listed companies and consultants. It has been.',\n",
        "  '■ COMMENT',\n",
        "  'Jerome Williams (a professor at Rutgers University) - It\\'s a good approach. You shouldn\\'t really profile. You should behaviorally profile.',\n",
        "  '■ ABOUT OUR OFFERING',\n",
        "  '[ VAAK Technology 3 Division ] ',\n",
        "  '1 Behavioral analysis common base \"VAAKBASE\"',\n",
        "  '2 Crime prevention AI \"VAAKEYE\" (domestic / overseas) ',\n",
        "  '3 Unmanned cash register \"VAAKPAY\"',\n",
        "  '[ Recruited Position ] ',\n",
        "  '- Software Engineer',\n",
        "  '- R&D Engineer',\n",
        "  '[ Major areas of work ]',\n",
        "  '- architect and coding of base system and products',\n",
        "  '- Engineering (1+ from the followings):',\n",
        "  '--- VAAKBASE: Behavior detection, Tracking system, API for Web UI (provide Video, Data)',\n",
        "  '--- VAAKEYE(security&marketing): Detect&Alert system',\n",
        "  '--- VAAKPAY: Management system for Shelf, Customer and Items.',\n",
        "  '- Research: (1+ from the followings):',\n",
        "  '--- Behavior detection/prediction, Face recognition, Gait recognition, Pose estimation, People Tracking, Object recognition',\n",
        "  '- Team building and documentation',\n",
        "  '- 2nd mission: you can do other domain jobs if you want',\n",
        "  '[ Required condition A (1+ from the followings) ] ',\n",
        "  '- Deep learning algorithm development for images and time series (1+ from the followings):',\n",
        "  '--- behavior judgment / prediction · face recognition · gait recognition · POSE estimation · Tracking, object identification, mapping',\n",
        "  '- System development (Python) * Software Engineer required ',\n",
        "  '- Compiler and GPU software development ',\n",
        "  '- Automation and Quality Assurance',\n",
        "  '[ Required Condition B ] ',\n",
        "  '- Ability to agree with VISION and VALUE',\n",
        "  '- At least 2 year\\'s work experience in the work area and surrounding area',\n",
        "  '[ Technical Environment ] ',\n",
        "  '- Langage: Python, Ruby, C ++ ',\n",
        "  '- Framework: Keras, tensorflow, Rails, Bootstrap ',\n",
        "  '- Versioning: Git ',\n",
        "  '- Cloud: AWS , GCP ',\n",
        "  '- Repository: Bitbucket ',\n",
        "  '- Communication: Slack ',\n",
        "  '- CI: CircleCI ',\n",
        "  '- Monitoring: Datadog , NewRelic ',\n",
        "  '- Error Monitoring: Sentry ',\n",
        "  '- DB: MySQL, Redis',\n",
        "  '[ others ]',\n",
        "  '- Visa Support',\n",
        "  'We are waiting for your application. At first, please feel free to apply!'    \n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Dq_VHRzFe79",
        "outputId": "3164842c-ca94-4316-cedf-1e84014184a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Load infersent model \n",
        "model_version = 2\n",
        "MODEL_PATH = \"encoder/infersent%s.pkl\" % model_version\n",
        "params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048, 'pool_type': 'max', 'dpout_model': 0.0, 'version': model_version}\n",
        "\n",
        "model = InferSent(params_model)\n",
        "model.load_state_dict(torch.load(MODEL_PATH))\n",
        "\n",
        "W2V_PATH = 'fastText/crawl-300d-2M.vec'\n",
        "model.set_w2v_path(W2V_PATH)\n",
        "\n",
        "# generate infersent sentence embeddings\n",
        "model.build_vocab(sentences, tokenize=True)\n",
        "embs = model.encode(sentences, tokenize=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 897(/918) words with w2v vectors\n",
            "Vocab size : 897\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "b73d2efd-e41f-4155-c81f-5cfff4d2c550",
        "id": "50qX3J6raZYy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "InferSent(\n",
              "  (enc_lstm): LSTM(300, 2048, bidirectional=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "840ba7bc-c4c2-4935-9521-c85d634964ed",
        "id": "M9oaAMMVaYnF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!mkdir '../gdrive/My Drive/model'\n",
        "!ls 'gdrive/My Drive/model'\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access 'gdrive/My Drive/model': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "cfdfe54d-08cb-40ce-b7d8-99231304f0fb",
        "id": "bLKx2UenaWyF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! ls 'gdrive'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access 'gdrive': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uy1wmdkTaWYj"
      },
      "source": [
        "torch.save(model.state_dict(), 'model.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "4271a24a-8780-4544-8ec2-7aee4f84ffcb",
        "id": "MqD4ZFBlaWEY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encoder  fastText  InferSent  model  model.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkFzxPDvaVnQ"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('model.pt') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaeNGClXb9dO"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('example.txt') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbAjiBoRGjxC"
      },
      "source": [
        "NTHREADS = 8\n",
        "def create_index(a):\n",
        "    index = nmslib.init(space='angulardist')\n",
        "    index.addDataPointBatch(a)\n",
        "    index.createIndex()\n",
        "    return index\n",
        "\n",
        "def get_knns(index, vecs, k=3):\n",
        "    return zip(*index.knnQueryBatch(vecs, k=k, num_threads=NTHREADS))\n",
        "\n",
        "nn_wvs = create_index(embs)\n",
        "to_frame = lambda x: pd.DataFrame(np.array(x)[:,1:])\n",
        "idxs, dists = map(to_frame, get_knns(nn_wvs, embs, k=3))\n",
        "catted = pd.concat([idxs.stack().to_frame('idx'), dists.stack().to_frame('dist')], axis=1).reset_index().drop('level_1',1).rename(columns={'level_0': 'v1', 'idx': 'v2'})\n",
        "\n",
        "indices, distances = np.vstack(idxs), np.vstack(dists)\n",
        "n_samples_transform = embs.shape[0]\n",
        "n_neighbors = 3\n",
        "indptr = np.arange(0, n_samples_transform * n_neighbors + 1, n_neighbors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHCmhIX4G-k6"
      },
      "source": [
        "kmeans = KMeans(n_clusters=3)\n",
        "kmeans.fit(embs)\n",
        "y_km = kmeans.fit_predict(embs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTZfXn3cHH0h"
      },
      "source": [
        "first_cluster = [x for idx, x in enumerate(sentences) if y_km[idx] == 0]\n",
        "for x in first_cluster: print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5YOCNeiHIeF"
      },
      "source": [
        "second_cluster = [x for idx, x in enumerate(sentences) if y_km[idx] == 1]\n",
        "for x in second_cluster: print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cB6xdrwHI2V"
      },
      "source": [
        "third_cluster = [x for idx, x in enumerate(sentences) if y_km[idx] == 2]\n",
        "for x in third_cluster: print(x)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}